@article{nahar2024beyond,
  title={Beyond the Comfort Zone: Emerging Solutions to Overcome Challenges in Integrating LLMs into Software Products},
  author={Nahar, Nadia and K{\"a}stner, Christian and Butler, Jenna and Parnin, Chris and Zimmermann, Thomas and Bird, Christian},
  journal={arXiv preprint arXiv:2410.12071},
  year={2024}
}

@article{szymanski2024comparing,
  title={Comparing Criteria Development Across Domain Experts, Lay Users, and Models in Large Language Model Evaluation},
  author={Szymanski, Annalisa and Gebreegziabher, Simret Araya and Anuyah, Oghenemaro and Metoyer, Ronald A and Li, Toby Jia-Jun},
  journal={arXiv preprint arXiv:2410.02054},
  year={2024}
}

@inproceedings{kim2024evallm,
  title={Evallm: Interactive evaluation of large language model prompts on user-defined criteria},
  author={Kim, Tae Soo and Lee, Yoonjoo and Shin, Jamin and Kim, Young-Ho and Kim, Juho},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2024}
}

@inproceedings{arawjo2024chainforge,
  title={Chainforge: A visual toolkit for prompt engineering and llm hypothesis testing},
  author={Arawjo, Ian and Swoopes, Chelse and Vaithilingam, Priyan and Wattenberg, Martin and Glassman, Elena L},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  year={2024}
}

@article{shen2024towards,
  title={Towards bidirectional human-ai alignment: A systematic review for clarifications, framework, and future directions},
  author={Shen, Hua and Knearem, Tiffany and Ghosh, Reshmi and Alkiek, Kenan and Krishna, Kundan and Liu, Yachuan and Ma, Ziqiao and Petridis, Savvas and Peng, Yi-Hao and Qiwei, Li and others},
  journal={arXiv preprint arXiv:2406.09264},
  year={2024}
}

@article{sivaraman2025divisi,
  title={Divisi: Interactive Search and Visualization for Scalable Exploratory Subgroup Analysis},
  author={Sivaraman, Venkatesh and Li, Zexuan and Perer, Adam},
  journal={arXiv preprint arXiv:2502.10537},
  year={2025}
}


@inproceedings{wu2023scattershot,
author = {Wu, Sherry and Shen, Hua and Weld, Daniel S and Heer, Jeffrey and Ribeiro, Marco Tulio},
title = {ScatterShot: Interactive In-Context Example Curation for Text Transformation},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581641.3584059},
doi = {10.1145/3581641.3584059},
abstract = {The in-context learning capabilities of LLMs like GPT-3 allow annotators to customize an LLM to their specific tasks with a small number of examples. However, users tend to include only the most obvious patterns when crafting examples, resulting in underspecified in-context functions that fall short on unseen cases. Further, it is hard to know when “enough” examples have been included even for known patterns. In this work, we present ScatterShot, an interactive system for building high-quality demonstration sets for in-context learning. ScatterShot iteratively slices unlabeled data into task-specific patterns, samples informative inputs from underexplored or not-yet-saturated slices in an active learning manner, and helps users label more efficiently with the help of an LLM and the current example set. In simulation studies on two text perturbation scenarios, ScatterShot sampling improves the resulting few-shot functions by 4-5 percentage points over random sampling, with less variance as more examples are added. In a user study, ScatterShot greatly helps users in covering different patterns in the input space and labeling in-context examples more efficiently, resulting in better in-context learning and less user effort.},
booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {353–367},
numpages = {15},
location = {Sydney, NSW, Australia},
series = {IUI '23}
}

@article{ribeiro2020beyond,
  title={Beyond accuracy: Behavioral testing of NLP models with CheckList},
  author={Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  journal={arXiv preprint arXiv:2005.04118},
  year={2020}
}

@article{wu2021polyjuice,
  title={Polyjuice: Generating counterfactuals for explaining, evaluating, and improving models},
  author={Wu, Tongshuang and Ribeiro, Marco Tulio and Heer, Jeffrey and Weld, Daniel S},
  journal={arXiv preprint arXiv:2101.00288},
  year={2021}
}

@inproceedings{ribeiro2022adaptive,
  title={Adaptive testing and debugging of NLP models},
  author={Ribeiro, Marco Tulio and Lundberg, Scott},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3253--3267},
  year={2022}
}

@inproceedings{cabrera2023zeno,
author = {Cabrera, \'{A}ngel Alexander and Fu, Erica and Bertucci, Donald and Holstein, Kenneth and Talwalkar, Ameet and Hong, Jason I. and Perer, Adam},
title = {Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581268},
doi = {10.1145/3544548.3581268},
abstract = {Machine learning models with high accuracy on test data can still produce systematic failures, such as harmful biases and safety issues, when deployed in the real world. To detect and mitigate such failures, practitioners run behavioral evaluation of their models, checking model outputs for specific types of inputs. Behavioral evaluation is important but challenging, requiring that practitioners discover real-world patterns and validate systematic failures. We conducted 18 semi-structured interviews with ML practitioners to better understand the challenges of behavioral evaluation and found that it is a collaborative, use-case-first process that is not adequately supported by existing task- and domain-specific tools. Using these findings, we designed zeno, a general-purpose framework for visualizing and testing AI systems across diverse use cases. In four case studies with participants using zeno on real-world models, we found that practitioners were able to reproduce previous manual analyses and discover new systematic failures.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {419},
numpages = {14},
keywords = {testing, evaluation, machine learning, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{robertson2023angler,
author = {Robertson, Samantha and Wang, Zijie J. and Moritz, Dominik and Kery, Mary Beth and Hohman, Fred},
title = {Angler: Helping Machine Translation Practitioners Prioritize Model Improvements},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580790},
doi = {10.1145/3544548.3580790},
abstract = {Machine learning (ML) models can fail in unexpected ways in the real world, but not all model failures are equal. With finite time and resources, ML practitioners are forced to prioritize their model debugging and improvement efforts. Through interviews with 13 ML practitioners at Apple, we found that practitioners construct small targeted test sets to estimate an error’s nature, scope, and impact on users. We built on this insight in a case study with machine translation models, and developed Angler, an interactive visual analytics tool to help practitioners prioritize model improvements. In a user study with 7 machine translation experts, we used Angler to understand prioritization practices when the input space is infinite, and obtaining reliable signals of model quality is expensive. Our study revealed that participants could form more interesting and user-focused hypotheses for prioritization by analyzing quantitative summary statistics and qualitatively assessing data by reading sentences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {832},
numpages = {20},
keywords = {visual analytics, Model evaluation, machine translation},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{wu2019errudite,
    title = "{E}rrudite: Scalable, Reproducible, and Testable Error Analysis",
    author = "Wu, Tongshuang  and
      Ribeiro, Marco Tulio  and
      Heer, Jeffrey  and
      Weld, Daniel",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1073",
    doi = "10.18653/v1/P19-1073",
    pages = "747--763",
    abstract = "Though error analysis is crucial to understanding and improving NLP models, the common practice of manual, subjective categorization of a small sample of errors can yield biased and incomplete conclusions. This paper codifies model and task agnostic principles for informative error analysis, and presents Errudite, an interactive tool for better supporting this process. First, error groups should be precisely defined for reproducibility; Errudite supports this with an expressive domain-specific language. Second, to avoid spurious conclusions, a large set of instances should be analyzed, including both positive and negative examples; Errudite enables systematic grouping of relevant instances with filtering queries. Third, hypotheses about the cause of errors should be explicitly tested; Errudite supports this via automated counterfactual rewriting. We validate our approach with a user study, finding that Errudite (1) enables users to perform high quality and reproducible error analyses with less effort, (2) reveals substantial ambiguities in prior published error analyses practices, and (3) enhances the error analysis experience by allowing users to test and revise prior beliefs.",
}

@article{wexler2020whatif,
  author={Wexler, James and Pushkarna, Mahima and Bolukbasi, Tolga and Wattenberg, Martin and Viégas, Fernanda and Wilson, Jimbo},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={The What-If Tool: Interactive Probing of Machine Learning Models}, 
  year={2020},
  volume={26},
  number={1},
  pages={56-65},
  doi={10.1109/TVCG.2019.2934619}
}

@article{mishra2023promptaid,
  title={PromptAid: Prompt Exploration, Perturbation, Testing and Iteration using Visual Analytics for Large Language Models},
  author={Mishra, Aditi and Soni, Utkarsh and Arunkumar, Anjana and Huang, Jinbin and Kwon, Bum Chul and Bryan, Chris},
  journal={arXiv preprint arXiv:2304.01964},
  year={2023}
}


@inproceedings{zamfirescu2023herding,
author = {Zamfirescu-Pereira, J.D. and Wei, Heather and Xiao, Amy and Gu, Kitty and Jung, Grace and Lee, Matthew G and Hartmann, Bjoern and Yang, Qian},
title = {Herding AI Cats: Lessons from Designing a Chatbot by Prompting GPT-3},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596138},
doi = {10.1145/3563657.3596138},
abstract = {Prompting Large Language Models (LLMs) is an exciting new approach to designing chatbots. But can it improve LLM’s user experience (UX) reliably enough to power chatbot products? Our attempt to design a robust chatbot by prompting GPT-3/4 alone suggests: not yet. Prompts made achieving “80\%” UX goals easy, but not the remaining 20\%. Fixing the few remaining interaction breakdowns resembled herding cats: We could not address one UX issue or test one design solution at a time; instead, we had to handle everything everywhere all at once. Moreover, because no prompt could make GPT reliably say “I don’t know” when it should, the user-GPT conversations had no guardrails after a breakdown occurred, often leading to UX downward spirals. These risks incentivized us to design highly prescriptive prompts and scripted bots, counter to the promises of LLM-powered chatbots. This paper describes this case study, unpacks prompting’s fickleness and its impact on UX design processes, and discusses implications for LLM-based design methods and tools.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {2206–2220},
numpages = {15},
keywords = {GPT., UX, conversational user interface, Prompt engineering},
location = {Pittsburgh, PA, USA},
series = {DIS '23}
}

@inproceedings{liu2023what,
author = {Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
title = {“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580817},
doi = {10.1145/3544548.3580817},
abstract = {Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user’s natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users’ understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {598},
numpages = {31},
keywords = {Large Language Models, Spreadsheets, Human-AI Interaction, Natural Language Programming},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{wu2022aichains,
author = {Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun},
title = {AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517582},
doi = {10.1145/3491102.3517582},
abstract = {Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by “unit-testing” sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {385},
numpages = {22},
keywords = {Natural Language Processing, Large Language Models, Human-AI Interaction},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{kim2023cells,
  author = {Kim, Tae Soo and Lee, Yoonjoo and Chang, Minsuk and Kim, Juho},
  title = {Cells, Generators, and Lenses: Design Framework for Object-Oriented Interaction with Large Language Models},
  year = {2023},
  isbn = {9798400701320},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3586183.3606833},
  doi = {10.1145/3586183.3606833},
  booktitle = {The 36th Annual ACM Symposium on User Interface Software and Technology (UIST '23), October 29-November 1, 2023, San Francisco, CA, USA},
  numpages = {18},
  location = {San Francisco, CA, USA},
  series = {UIST '23}
}

@ARTICLE{strobelt2023promptide,
  author={Strobelt, Hendrik and Webson, Albert and Sanh, Victor and Hoover, Benjamin and Beyer, Johanna and Pfister, Hanspeter and Rush, Alexander M.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models}, 
  year={2023},
  volume={29},
  number={1},
  pages={1146-1156},
  doi={10.1109/TVCG.2022.3209479}
}

@misc{zheng2023judging,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{zhang2024chainbuddy,
  title={ChainBuddy: An AI Agent System for Generating LLM Pipelines},
  author={Zhang, Jingyue and Arawjo, Ian},
  journal={arXiv preprint arXiv:2409.13588},
  year={2024}
}

@article{kahng2024llm,
  title={LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models},
  author={Kahng, Minsuk and Tenney, Ian and Pushkarna, Mahima and Liu, Michael Xieyang and Wexler, James and Reif, Emily and Kallarackal, Krystal and Chang, Minsuk and Terry, Michael and Dixon, Lucas},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2024},
  publisher={IEEE}
}

@inproceedings{shankar2024validates,
  title={Who validates the validators? aligning llm-assisted evaluation of llm outputs with human preferences},
  author={Shankar, Shreya and Zamfirescu-Pereira, JD and Hartmann, Bj{\"o}rn and Parameswaran, Aditya and Arawjo, Ian},
  booktitle={Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--14},
  year={2024}
}

@article{ashktorab2024aligning,
  title={Aligning Human and LLM Judgments: Insights from EvalAssist on Task-Specific Evaluations and AI-assisted Assessment Strategy Preferences},
  author={Ashktorab, Zahra and Desmond, Michael and Pan, Qian and Johnson, James M and Cooper, Martin Santillan and Daly, Elizabeth M and Nair, Rahul and Pedapati, Tejaswini and Achintalwar, Swapnaja and Geyer, Werner},
  journal={arXiv preprint arXiv:2410.00873},
  year={2024}
}

@article{lam2024ai,
  title={AI Policy Projector: Grounding LLM Policy Design in Iterative Mapmaking},
  author={Lam, Michelle S and Hohman, Fred and Moritz, Dominik and Bigham, Jeffrey P and Holstein, Kenneth and Kery, Mary Beth},
  journal={arXiv preprint arXiv:2409.18203},
  year={2024}
}

@article{epperson2025interactive,
  title={Interactive Debugging and Steering of Multi-Agent AI Systems},
  author={Epperson, Will and Bansal, Gagan and Dibia, Victor and Fourney, Adam and Gerrits, Jack and Zhu, Erkang and Amershi, Saleema},
  journal={arXiv preprint arXiv:2503.02068},
  year={2025}
}

@inproceedings{lam2024concept,
  title={Concept induction: Analyzing unstructured text with high-level concepts using lloom},
  author={Lam, Michelle S and Teoh, Janice and Landay, James A and Heer, Jeffrey and Bernstein, Michael S},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  pages={1--28},
  year={2024}
}

@inproceedings{suh2024luminate,
  title={Luminate: Structured generation and exploration of design space with large language models for human-ai co-creation},
  author={Suh, Sangho and Chen, Meng and Min, Bryan and Li, Toby Jia-Jun and Xia, Haijun},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  pages={1--26},
  year={2024}
}

@inproceedings{gero2024supporting,
  title={Supporting sensemaking of large language model outputs at scale},
  author={Gero, Katy Ilonka and Swoopes, Chelse and Gu, Ziwei and Kummerfeld, Jonathan K and Glassman, Elena L},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2024}
}

@article{wang2023wizmap,
  title={Wizmap: Scalable interactive visualization for exploring large machine learning embeddings},
  author={Wang, Zijie J and Hohman, Fred and Chau, Duen Horng},
  journal={arXiv preprint arXiv:2306.09328},
  year={2023}
}

@article{glassman2015overcode,
  title={OverCode: Visualizing variation in student solutions to programming problems at scale},
  author={Glassman, Elena L and Scott, Jeremy and Singh, Rishabh and Guo, Philip J and Miller, Robert C},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={22},
  number={2},
  pages={1--35},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@article{kim2016topiclens,
  title={Topiclens: Efficient multi-level visual topic exploration of large-scale document collections},
  author={Kim, Minjeong and Kang, Kyeongpil and Park, Deokgun and Choo, Jaegul and Elmqvist, Niklas},
  journal={IEEE transactions on visualization and computer graphics},
  volume={23},
  number={1},
  pages={151--160},
  year={2016},
  publisher={IEEE}
}

@inproceedings{yatani2011review,
  title={Review spotlight: a user interface for summarizing user-generated reviews using adjective-noun word pairs},
  author={Yatani, Koji and Novati, Michael and Trusty, Andrew and Truong, Khai N},
  booktitle={Proceedings of the SIGCHI conference on human factors in computing systems},
  pages={1541--1550},
  year={2011}
}

@article{ye2023flask,
  title={Flask: Fine-grained language model evaluation based on alignment skill sets},
  author={Ye, Seonghyeon and Kim, Doyoung and Kim, Sungdong and Hwang, Hyeonbin and Kim, Seungone and Jo, Yongrae and Thorne, James and Kim, Juho and Seo, Minjoon},
  journal={arXiv preprint arXiv:2307.10928},
  year={2023}
}

@article{wu2023fine,
    title={Fine-Grained Human Feedback Gives Better Rewards for Language Model Training},
    author={Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith,
    Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh},
    journal={arXiv preprint arXiv:2306.01693},
    year={2023}
}

@article{lambert2024rewardbench,
  title={Rewardbench: Evaluating reward models for language modeling},
  author={Lambert, Nathan and Pyatkin, Valentina and Morrison, Jacob and Miranda, LJ and Lin, Bill Yuchen and Chandu, Khyathi and Dziri, Nouha and Kumar, Sachin and Zick, Tom and Choi, Yejin and others},
  journal={arXiv preprint arXiv:2403.13787},
  year={2024}
}

@article{dou2021gpt,
  title={Is GPT-3 text indistinguishable from human text? scarecrow: A framework for scrutinizing machine text},
  author={Dou, Yao and Forbes, Maxwell and Koncel-Kedziorski, Rik and Smith, Noah A and Choi, Yejin},
  journal={arXiv preprint arXiv:2107.01294},
  year={2021}
}

@article{perlman2003performance,
  title={Performance Assessment: Designing Appropriate Performance Tasks and Scoring Rubrics.},
  author={Perlman, Carole C},
  year={2003},
  publisher={ERIC}
}

@article{thomas2006general,
  title={A general inductive approach for analyzing qualitative evaluation data},
  author={Thomas, David R},
  journal={American journal of evaluation},
  volume={27},
  number={2},
  pages={237--246},
  year={2006},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@inproceedings{suh2023sensecape,
  title={Sensecape: Enabling multilevel exploration and sensemaking with large language models},
  author={Suh, Sangho and Min, Bryan and Palani, Srishti and Xia, Haijun},
  booktitle={Proceedings of the 36th annual ACM symposium on user interface software and technology},
  pages={1--18},
  year={2023}
}

@inproceedings{palani2021conotate,
  title={CoNotate: Suggesting queries based on notes promotes knowledge discovery},
  author={Palani, Srishti and Ding, Zijian and Nguyen, Austin and Chuang, Andrew and MacNeil, Stephen and Dow, Steven P},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2021}
}

@inproceedings{palani2022interweave,
  title={InterWeave: Presenting Search Suggestions in Context Scaffolds Information Search and Synthesis},
  author={Palani, Srishti and Zhou, Yingyi and Zhu, Sheldon and Dow, Steven P},
  booktitle={Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--16},
  year={2022}
}

@inproceedings{jiang2023graphologue,
  title={Graphologue: Exploring large language model responses with interactive diagrams},
  author={Jiang, Peiling and Rayan, Jude and Dow, Steven P and Xia, Haijun},
  booktitle={Proceedings of the 36th annual ACM symposium on user interface software and technology},
  pages={1--20},
  year={2023}
}

@article{zeng2025evaltree,
  title={EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees},
  author={Zeng, Zhiyuan and Wang, Yizhong and Hajishirzi, Hannaneh and Koh, Pang Wei},
  journal={arXiv preprint arXiv:2503.08893},
  year={2025}
}

@article{murahari2023qualeval,
  title={Qualeval: Qualitative evaluation for model improvement},
  author={Murahari, Vishvak and Deshpande, Ameet and Clark, Peter and Rajpurohit, Tanmay and Sabharwal, Ashish and Narasimhan, Karthik and Kalyan, Ashwin},
  journal={arXiv preprint arXiv:2311.02807},
  year={2023}
}

@misc{karpathy2025tweet,
  author = {Karpathy, Andrej [@karpathy]},
  title = {My reaction is that there is an evaluation crisis. I don't really know what metrics to look at right now. [...] In absence of great comprehensive evals I tried to turn to vibe checks instead, but I now fear they are misleading and there is too much opportunity for confirmation bias, too low sample size, etc., it's just not great. TLDR my reaction is I don't really know how good these models are right now.},
  howpublished = {\url{https://x.com/karpathy/status/1896266683301659068}},
  year = {2025},
  month = {Mar},
  day = {3},
  note = {Accessed: 2025-04-01}
}


@article{dunlap2024vibecheck,
  title={VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models},
  author={Dunlap, Lisa and Mandal, Krishna and Darrell, Trevor and Steinhardt, Jacob and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2410.12851},
  year={2024}
}

@misc{openthoughts,
  author = {Team, OpenThoughts},
  month = jan,
  title = {{Open Thoughts}},
  howpublished = {https://open-thoughts.ai},
  year = {2025}
}

@misc{bhardwaj2023redteaming,
      title={Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment}, 
      author={Rishabh Bhardwaj and Soujanya Poria},
      year={2023},
      eprint={2308.09662},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}

@article{park2024generative,
  title={Generative agent simulations of 1,000 people},
  author={Park, Joon Sung and Zou, Carolyn Q and Shaw, Aaron and Hill, Benjamin Mako and Cai, Carrie and Morris, Meredith Ringel and Willer, Robb and Liang, Percy and Bernstein, Michael S},
  journal={arXiv preprint arXiv:2411.10109},
  year={2024}
}

@article{wang2024sotopia,
  title={SOTOPIA-$\pi$: Interactive Learning of Socially Intelligent Language Agents},
  author={Wang, Ruiyi and Yu, Haofei and Zhang, Wenxin and Qi, Zhengyang and Sap, Maarten and Neubig, Graham and Bisk, Yonatan and Zhu, Hao},
  journal={arXiv preprint arXiv:2403.08715},
  year={2024}
}

@article{zhou2023sotopia,
  title={Sotopia: Interactive evaluation for social intelligence in language agents},
  author={Zhou, Xuhui and Zhu, Hao and Mathur, Leena and Zhang, Ruohong and Yu, Haofei and Qi, Zhengyang and Morency, Louis-Philippe and Bisk, Yonatan and Fried, Daniel and Neubig, Graham and others},
  journal={arXiv preprint arXiv:2310.11667},
  year={2023}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{jaech2024openai,
  title={Openai o1 system card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{lu2024ai,
  title={The ai scientist: Towards fully automated open-ended scientific discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}

@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@article{starace2025paperbench,
  title={PaperBench: Evaluating AI's Ability to Replicate AI Research},
  author={Starace, Giulio and Jaffe, Oliver and Sherburn, Dane and Aung, James and Chan, Jun Shern and Maksin, Leon and Dias, Rachel and Mays, Evan and Kinsella, Benjamin and Thompson, Wyatt and others},
  journal={arXiv preprint arXiv:2504.01848},
  year={2025}
}

@inproceedings{yuan2022wordcraft,
  title={Wordcraft: story writing with large language models},
  author={Yuan, Ann and Coenen, Andy and Reif, Emily and Ippolito, Daphne},
  booktitle={Proceedings of the 27th International Conference on Intelligent User Interfaces},
  pages={841--852},
  year={2022}
}

@inproceedings{chung2022talebrush,
  title={TaleBrush: Sketching stories with generative pretrained language models},
  author={Chung, John Joon Young and Kim, Wooseok and Yoo, Kang Min and Lee, Hwaran and Adar, Eytan and Chang, Minsuk},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2022}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@inproceedings{yao2023react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM computing surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{gebreegziabher2025metricmate,
  title={MetricMate: An Interactive Tool for Generating Evaluation Criteria for LLM-as-a-Judge Workflow},
  author={Gebreegziabher, Simret Araya and Chiang, Charles and Wang, Zichu and Ashktorab, Zahra and Brachman, Michelle and Geyer, Werner and Li, Toby Jia-Jun and G{\'o}mez-Zar{\'a}, Diego},
  year={2025}
}

@inproceedings{kim2023prometheus,
  title={Prometheus: Inducing fine-grained evaluation capability in language models},
  author={Kim, Seungone and Shin, Jamin and Cho, Yejin and Jang, Joel and Longpre, Shayne and Lee, Hwaran and Yun, Sangdoo and Shin, Seongjin and Kim, Sungdong and Thorne, James and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{kim2024biggen,
  title={The biggen bench: A principled benchmark for fine-grained evaluation of language models with language models},
  author={Kim, Seungone and Suk, Juyoung and Cho, Ji Yong and Longpre, Shayne and Kim, Chaeeun and Yoon, Dongkeun and Son, Guijin and Cho, Yejin and Shafayat, Sheikh and Baek, Jinheon and others},
  journal={arXiv preprint arXiv:2406.05761},
  year={2024}
}

@article{lin2024wildbench,
  title={Wildbench: Benchmarking llms with challenging tasks from real users in the wild},
  author={Lin, Bill Yuchen and Deng, Yuntian and Chandu, Khyathi and Brahman, Faeze and Ravichander, Abhilasha and Pyatkin, Valentina and Dziri, Nouha and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2406.04770},
  year={2024}
}

@article{saad2024lmunit,
  title={Lmunit: Fine-grained evaluation with natural language unit tests},
  author={Saad-Falcon, Jon and Vivek, Rajan and Berrios, William and Naik, Nandita Shankar and Franklin, Matija and Vidgen, Bertie and Singh, Amanpreet and Kiela, Douwe and Mehri, Shikib},
  journal={arXiv preprint arXiv:2412.13091},
  year={2024}
}

@misc{bai2024implicit,
      title={Measuring Implicit Bias in Explicitly Unbiased Large Language Models}, 
      author={Xuechunzi Bai and Angelina Wang and Ilia Sucholutsky and Thomas L. Griffiths},
      year={2024},
      eprint={2402.04105},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2402.04105}, 
}

@inproceedings{brown2020few,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{tamkin2024clio,
  title={Clio: Privacy-Preserving Insights into Real-World AI Use},
  author={Tamkin, Alex and McCain, Miles and Handa, Kunal and Durmus, Esin and Lovitt, Liane and Rathi, Ankur and Huang, Saffron and Mountfield, Alfred and Hong, Jerry and Ritchie, Stuart and others},
  journal={arXiv preprint arXiv:2412.13678},
  year={2024}
}

@article{mcinnes2017hdbscan,
  title={hdbscan: Hierarchical density based clustering.},
  author={McInnes, Leland and Healy, John and Astels, Steve and others},
  journal={J. Open Source Softw.},
  volume={2},
  number={11},
  pages={205},
  year={2017}
}

@article{lloyd1982kmeans,
  title={Least squares quantization in PCM},
  author={Lloyd, Stuart},
  journal={IEEE transactions on information theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}

@inproceedings{macqueen1967kmeans,
  title={Some methods for classification and analysis of multivariate observations},
  author={MacQueen, James},
  booktitle={Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics},
  volume={5},
  pages={281--298},
  year={1967},
  organization={University of California press}
}

@article{mcinnes2018umap,
  title={Umap: Uniform manifold approximation and projection for dimension reduction},
  author={McInnes, Leland and Healy, John and Melville, James},
  journal={arXiv preprint arXiv:1802.03426},
  year={2018}
}

@misc{deyoung2020eraser,
      title={ERASER: A Benchmark to Evaluate Rationalized NLP Models}, 
      author={Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace},
      year={2020},
      eprint={1911.03429},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1911.03429}, 
}

@misc{anthropic2025claude37,
  author    = {Anthropic},
  title     = {Claude 3.7 Sonnet and Claude Code},
  year      = {2025},
  url       = {https://www.anthropic.com/news/claude-3-7-sonnet},
  note      = {Accessed: 2025-03-19},
}

@article{cabrera2023did,
  title={What did my AI learn? How data scientists make sense of model behavior},
  author={Cabrera, {\'A}ngel Alexander and Tulio Ribeiro, Marco and Lee, Bongshin and Deline, Robert and Perer, Adam and Drucker, Steven M},
  journal={ACM Transactions on Computer-Human Interaction},
  volume={30},
  number={1},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{lee2023dapie,
  title={DAPIE: interactive step-by-step explanatory dialogues to answer children’s why and how questions},
  author={Lee, Yoonjoo and Kim, Tae Soo and Kim, Sungdong and Yun, Yohan and Kim, Juho},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--22},
  year={2023}
}

@inproceedings{chau2011apolo,
  title={Apolo: making sense of large network data by combining rich user interaction and machine learning},
  author={Chau, Duen Horng and Kittur, Aniket and Hong, Jason I and Faloutsos, Christos},
  booktitle={Proceedings of the SIGCHI conference on human factors in computing systems},
  pages={167--176},
  year={2011}
}

@inproceedings{andre2014crowd,
  title={Crowd synthesis: Extracting categories and clusters from complex data},
  author={Andr{\'e}, Paul and Kittur, Aniket and Dow, Steven P},
  booktitle={Proceedings of the 17th ACM conference on Computer supported cooperative work \& social computing},
  pages={989--998},
  year={2014}
}

@inproceedings{liu2024selenite,
  title={Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models},
  author={Liu, Michael Xieyang and Wu, Tongshuang and Chen, Tianying and Li, Franklin Mingzhe and Kittur, Aniket and Myers, Brad A},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  pages={1--26},
  year={2024}
}

@inproceedings{rachatasumrit2021forsense,
  title={Forsense: Accelerating online research through sensemaking integration and machine research support},
  author={Rachatasumrit, Napol and Ramos, Gonzalo and Suh, Jina and Ng, Rachel and Meek, Christopher},
  booktitle={Proceedings of the 26th International Conference on Intelligent User Interfaces},
  pages={608--618},
  year={2021}
}

@inproceedings{pirolli2005sensemaking,
  title={The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis},
  author={Pirolli, Peter and Card, Stuart},
  booktitle={Proceedings of international conference on intelligence analysis},
  volume={5},
  number={1},
  pages={2--4},
  year={2005},
  organization={McLean, VA, USA}
}

@inproceedings{liao2020questioning,
  title={Questioning the AI: informing design practices for explainable AI user experiences},
  author={Liao, Q Vera and Gruen, Daniel and Miller, Sarah},
  booktitle={Proceedings of the 2020 CHI conference on human factors in computing systems},
  pages={1--15},
  year={2020}
}

@inproceedings{lai2019human,
  title={On human predictions with explanations and predictions of machine learning models: A case study on deception detection},
  author={Lai, Vivian and Tan, Chenhao},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={29--38},
  year={2019}
}

@inproceedings{kaur2022sensible,
  title={Sensible AI: Re-imagining interpretability and explainability using sensemaking theory},
  author={Kaur, Harmanpreet and Adar, Eytan and Gilbert, Eric and Lampe, Cliff},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={702--714},
  year={2022}
}

@inproceedings{wang2019designing,
  title={Designing theory-driven user-centric explainable AI},
  author={Wang, Danding and Yang, Qian and Abdul, Ashraf and Lim, Brian Y},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--15},
  year={2019}
}

@inproceedings{lee2024one,
  title={One vs. many: Comprehending accurate information from multiple erroneous and inconsistent AI generations},
  author={Lee, Yoonjoo and Son, Kihoon and Kim, Tae Soo and Kim, Jisu and Chung, John Joon Young and Adar, Eytan and Kim, Juho},
  booktitle={Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
  pages={2518--2531},
  year={2024}
}

@inproceedings{fok2024marco,
  title={Marco: Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models},
  author={Fok, Raymond and Lipka, Nedim and Sun, Tong and Siu, Alexa F},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  pages={1--20},
  year={2024}
}

@misc{manus,
  author       = {Meta},
  title        = {Manus: Hands On AI},
  year         = {2026},
  howpublished = {\url{https://manus.im}},
  note         = {Accessed: 2026-02-02}
}

@misc{genspark,
  author       = {Genspark AI},
  title        = {Genspark: Agents That Write Code and Explain It},
  year         = {2024},
  howpublished = {\url{https://genspark.ai/}},
  note         = {Accessed: 2025-04-10}
}

@misc{llama4,
  author       = {Meta AI},
  title        = {The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation},
  year         = {2025},
  howpublished = {\url{https://ai.meta.com/blog/llama-4-multimodal-intelligence/}},
  note         = {Accessed: 2026-02-02}
}


@misc{deepresearch,
  author       = {Google},
  title        = {Gemini Deep Research - your personal research assistant},
  year         = {2024},
  howpublished = {\url{https://gemini.google/overview/deep-research/}},
  note         = {Accessed: 2025-04-10}
}


@article{ding2024longrope,
  title={Longrope: Extending llm context window beyond 2 million tokens},
  author={Ding, Yiran and Zhang, Li Lyna and Zhang, Chengruidong and Xu, Yuanyuan and Shang, Ning and Xu, Jiahang and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2402.13753},
  year={2024}
}

@article{hsieh2024ruler,
  title={RULER: What's the Real Context Size of Your Long-Context Language Models?},
  author={Hsieh, Cheng-Ping and Sun, Simeng and Kriman, Samuel and Acharya, Shantanu and Rekesh, Dima and Jia, Fei and Zhang, Yang and Ginsburg, Boris},
  journal={arXiv preprint arXiv:2404.06654},
  year={2024}
}

@article{kim2025scaling,
  title={Scaling Evaluation-time Compute with Reasoning Models as Process Evaluators},
  author={Kim, Seungone and Wu, Ian and Lee, Jinu and Yue, Xiang and Lee, Seongyun and Moon, Mingyeong and Gashteovski, Kiril and Lawrence, Carolin and Hockenmaier, Julia and Neubig, Graham and others},
  journal={arXiv preprint arXiv:2503.19877},
  year={2025}
}

@article{zhong2022unieval,
  title={Towards a unified multi-dimensional evaluator for text generation},
  author={Zhong, Ming and Liu, Yang and Yin, Da and Mao, Yuning and Jiao, Yizhu and Liu, Pengfei and Zhu, Chenguang and Ji, Heng and Han, Jiawei},
  journal={arXiv preprint arXiv:2210.07197},
  year={2022}
}

@article{liu2023geval,
  title={G-eval: NLG evaluation using gpt-4 with better human alignment},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  journal={arXiv preprint arXiv:2303.16634},
  year={2023}
}

@article{fu2023gptscore,
  title={Gptscore: Evaluate as you desire},
  author={Fu, Jinlan and Ng, See-Kiong and Jiang, Zhengbao and Liu, Pengfei},
  journal={arXiv preprint arXiv:2302.04166},
  year={2023}
}

@inproceedings{kittur2011crowdforge,
  title={Crowdforge: Crowdsourcing complex work},
  author={Kittur, Aniket and Smus, Boris and Khamkar, Susheel and Kraut, Robert E},
  booktitle={Proceedings of the 24th annual ACM symposium on User interface software and technology},
  pages={43--52},
  year={2011}
}

@inproceedings{min2023factscore,
  title={Factscore: Fine-grained atomic evaluation of factual precision in long form text generation},
  author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={12076--12100},
  year={2023}
}

@article{chang2023booookscore,
  title={Booookscore: A systematic exploration of book-length summarization in the era of llms},
  author={Chang, Yapei and Lo, Kyle and Goyal, Tanya and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2310.00785},
  year={2023}
}

@inproceedings{nenkova2004evaluating,
  title={Evaluating content selection in summarization: The pyramid method},
  author={Nenkova, Ani and Passonneau, Rebecca J},
  booktitle={Proceedings of the human language technology conference of the north american chapter of the association for computational linguistics: Hlt-naacl 2004},
  pages={145--152},
  year={2004}
}

@inproceedings{pu2025assistance,
  title={Assistance or disruption? exploring and evaluating the design and trade-offs of proactive ai programming support},
  author={Pu, Kevin and Lazaro, Daniel and Arawjo, Ian and Xia, Haijun and Xiao, Ziang and Grossman, Tovi and Chen, Yan},
  booktitle={Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2025}
}

@inproceedings{prasongpongchai2025talk,
  title={Talk to the Hand: an LLM-powered Chatbot with Visual Pointer as Proactive Companion for On-Screen Tasks},
  author={Prasongpongchai, Thanawit and Pataranutaporn, Pat and Lertsutthiwong, Monchai and Maes, Pattie},
  booktitle={Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2025}
}

@inproceedings{chen2025need,
  title={Need help? designing proactive ai assistants for programming},
  author={Chen, Valerie and Zhu, Alan and Zhao, Sebastian and Mozannar, Hussein and Sontag, David and Talwalkar, Ameet},
  booktitle={Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  year={2025}
}

@inproceedings{gu2025abstractexplorer,
  title={AbstractExplorer: Leveraging Structure-Mapping Theory to Enhance Comparative Close Reading at Scale},
  author={Gu, Ziwei and Zhou, Joyce and Lei, Ning-Er and Kummerfeld, Jonathan K and Jasim, Mahmood and Mahyar, Narges and Glassman, Elena L},
  booktitle={Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--25},
  year={2025}
}

@article{gentner1983structure,
  title={Structure-mapping: A theoretical framework for analogy},
  author={Gentner, Dedre},
  journal={Cognitive science},
  volume={7},
  number={2},
  pages={155--170},
  year={1983},
  publisher={Elsevier}
}

@inproceedings{ribeiro2016should,
  title={"Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{liao2021human,
  title={Human-centered explainable ai (xai): From algorithms to user experiences},
  author={Liao, Q Vera and Varshney, Kush R},
  journal={arXiv preprint arXiv:2110.10790},
  year={2021}
}

@inproceedings{lai2022human,
  title={Human-ai collaboration via conditional delegation: A case study of content moderation},
  author={Lai, Vivian and Carton, Samuel and Bhatnagar, Rajat and Liao, Q Vera and Zhang, Yunfeng and Tan, Chenhao},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  year={2022}
}

@article{wang2025opencua,
  title={Opencua: Open foundations for computer-use agents},
  author={Wang, Xinyuan and Wang, Bowen and Lu, Dunjie and Yang, Junlin and Xie, Tianbao and Wang, Junli and Deng, Jiaqi and Guo, Xiaole and Xu, Yiheng and Wu, Chen Henry and others},
  journal={arXiv preprint arXiv:2508.09123},
  year={2025}
}